{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Right Whale\n",
    "### <a href=\"https://www.kaggle.com/c/noaa-right-whale-recognition\">Kaggle Competition</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Walkthrough of the <a href=\"http://deepsense.io/deep-learning-right-whale-recognition-kaggle/\">competition winner's solution</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Team\n",
    "\n",
    "![](deepsense.png)\n",
    "\n",
    "<a href=\"www.deepsense.io\">DeepSense</a> are a deep learning solutions and consultancy company established by former employees of Google, Facebook, and Microsoft. \n",
    "\n",
    "Their machine learning team have a background in computer science and algorithms, rather than the more traditional fields of mathematics and statistics. They provide some interesting thoughts in this <a href=\"http://blog.kaggle.com/2016/01/29/noaa-right-whale-recognition-winners-interview-1st-place-deepsense-io/\">interview</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Competition\n",
    "\n",
    "![](competition.png)\n",
    "\n",
    "From aerial photos, identify whales from 447 individuals in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### North Atlantic Right Whales\n",
    "\n",
    "![](rightwhale.jpg)\n",
    "\n",
    "- So called because they were the \"right whale\" to hunt : **20m, 100t**\n",
    "- Less than **five hundred** left in the wild\n",
    "- Marine biologists concerned with conservation need to **identify individuals**\n",
    "- **Callosity** patterns on their heads are calcified skin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Callosity \n",
    "\n",
    "![background](background.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Competition\n",
    "\n",
    "- $10,000 prize\n",
    "- 11,469 images with varying resolutions and quality ( 9.5 GB )\n",
    "- Resolutions : 887x460 to 7010x4674; aspect ratios : 1.35 to 1.93\n",
    "- 447 individuals ( 1 - 40 images per individual )\n",
    "- Dataset contains cropped and rotated duplicates \"to discourage hand labelling\"; these do not count towards score\n",
    "- External data not allowed ( does this include pretrained models ? )\n",
    "- Goal : to provide a probability distribution over whales for each image\n",
    "- Scoring uses categorical cross-entropy ( multiclass logloss ) : \n",
    "\n",
    "$$\\mathrm{logloss} = -\\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^M y_{ij} \\log(p_{ij})$$\n",
    "\n",
    "where $y_{ij}$ is 1 if the observation $i$ belongs to individual $j$, and 0 otherwise; and $p_{ij}$ is the estimated probability of $i$ belonging to $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<a href=\"https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/\">This</a> is a great blog post on categorical cross-entropy loss compared with MSE and accuracy loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Issues with the Data\n",
    "\n",
    "<img src=\"data.png\"/>\n",
    "\n",
    "Images varied enormously in quality : sharpness, focus, colour, exposure and lighting conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*\"One does not need to see many images from the dataset in order to realize that whales do not pose very well (or at least were reluctant to do so in this particular case).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Compared with other Image Processing Challenges\n",
    "\n",
    "- The part of the image relevant to the solution occupies a small part of the image and may be occluded.\n",
    "- We can trivially recognise cats from dogs from motorbikes; even experts have trouble with this particular task.\n",
    "\n",
    "<img src=\"w206.jpg\" width=\"600px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Helping out our classifiers to focus on the correct features, i.e. the whaleâ€™s heads and their callosity patterns, turned out to be crucial.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solution\n",
    "\n",
    "### Software\n",
    "\n",
    "- Python with Theano for training\n",
    "- Sloth and Julia for labelling\n",
    "\n",
    "### Hardware\n",
    "\n",
    "- **NVIDIA Tesla K80**, 24 GB, 4992 cores at 560 MHz\n",
    "- **NVIDIA GRID K520**, 8 GB, 3072 cores at 800 MHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### General Solution : the whale \"passport photo\"\n",
    "\n",
    "![](passport.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Localising the Head\n",
    "\n",
    "The goal is to produce a bounding box containing the head.\n",
    "\n",
    "- Manually annotated all images with coordinates of a bounding box around the head\n",
    "- Resized images to 256x256\n",
    "- Trained not a regressor, but a classifier with pixels bins\n",
    "- Augmentation : 10 degree rotation, 0.8 - 1.2 scale factor, colour perturbation from Krizhevsky *et al.* on <a href=\"http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\">ImageNet</a>\n",
    "- Five CNNs : 20, 20, 40, 60, 128 bins\n",
    "- \"We combined the outputs from all the 5 networks.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"step1b.png\" style=\"width: 220px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](boundingbox.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Aligning the Head\n",
    "\n",
    "Images should have the the tip of the bonnet ( nose ) and the blowhead aligned consistently.\n",
    "\n",
    "- Manually annotated all images with \"bonnet-tip\" and \"blowhead\" and for callosity continuity\n",
    "- Takes as input the cropped image output from the previous CNN\n",
    "- Augmentation : 360 degree rotation, 4 pixel translation, 1 - 1.5 scale factor, random flip, color perturbation\n",
    "- Result is a 256x256 crop of the original image, containing bonnet-tip and blowhead points as the average output from five random augmentations\n",
    "- CNN also output a binary callosity continuity variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](aligner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](step1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](aligned.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Identifying Whales\n",
    "\n",
    "The output is a probability distribution that an image $i$ belongs to whale $j$.\n",
    "\n",
    "- Takes the 256x256 output from the previous CNN as input\n",
    "- Visual validation on the test dataset that head localisation and alignment algorithms performed well\n",
    "- Augmentation : 8 degrees rotation, 4 pixel translation, 1 - 1.3 scale factor, random flip, color perturbation\n",
    "- Pooling layers were 3x3 with 2-stride ( scale reduction 0.5x )\n",
    "- All convolutional layers were followed by batch normalisation\n",
    "- Nonlinearities were ReLU\n",
    "- Authors mention a 512x512 and bifurcating net \"in the final blend\"\n",
    "- CNN also outputs binary callosity continuity variable\n",
    "- Results are averaged over 20+ augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"finalnet.png\" width=\"95px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Additional Points\n",
    "\n",
    "- Initialisation : zero-mean, 0.01-std for conv layers; zero-mean, 0.001-std for dense layers\n",
    "- L2 regularisation : 0.0005 for conv layers, 0.01 - 0.05 for dense layers\n",
    "- SGD with 0.9 momentum, 500 - 1000 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fitting\n",
    "\n",
    "The additional callosity continuity target variable helped focus the net on the head and not elsewhere; this helped counter overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The learning rate had a slow decay, and was kicked during training. The best model was training using Nesterov momentum for 100 epochs and then Adam.\n",
    "\n",
    "<img src=\"train.png\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation\n",
    "\n",
    "- 90/10 split from the training dataset\n",
    "- Fixed random seed ( their favourite is 7300 )\n",
    "\n",
    "After settling on a model, retrained all models using full dataset :\n",
    "\n",
    "- Full retrain ( rarely )\n",
    "- 50 - 100 epochs using additional data ( often )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Results Hacks\n",
    "\n",
    "- Due to time constraints, no \"complex ensemble methods\" were used\n",
    "- The best model was better than an average of all models, until predicted probabilities were raised to 1.45\n",
    "- \"Small epsilon\" added to all probabilities\n",
    "- \"Slight skew\" according to whale distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Speed Hacks\n",
    "\n",
    "JPG encoding turned out to be very expensive :\n",
    "\n",
    "- Reading 111 images took 420ms\n",
    "- Reading 111 images and decoding to numpy array took ~10s\n",
    "- Solutions offered : decoding on GPU, or use other image formats\n",
    "\n",
    "Images were loaded to the GPU in parallel to allow efficient GPU use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Final Words from the Authors\n",
    "\n",
    "- Good quality crops generated in two steps ( head localisation, then alignment ) performed vastly better than when done in a single network\n",
    "- Manual annotation of callosity continuity was thought to be very important\n",
    "- Kicking the learning rate allowed for better training\n",
    "- \"Calibrating\" the probabilities by a power between 1.1 and 1.6 improved logloss by ~0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Word from me\n",
    "\n",
    "- There's a great deal of very solid work here, and a number of lessons to be learnt\n",
    "- There's also something close to cheating, but that's also the fault of the competition for asking for probabilities and not class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](atlantic2.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "livereveal": {
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
